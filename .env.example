# Plat Vlaamsâ€‘Only AI (lokaal / self-hosted)
#
# Kopieer naar `.env.local` en pas aan.

# Ollama (gratis/local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1
OLLAMA_TIMEOUT_S=20

# VlaamsCodex AI webserver (serveert `website/` + /api/chat)
VLAAMSCODEX_AI_HOST=127.0.0.1
VLAAMSCODEX_AI_PORT=5174
VLAAMSCODEX_WEB_ROOT=website

# Vercel:
# - `/api/chat` draait als serverless function (zie `website/api/chat.js`)
# - `OLLAMA_BASE_URL` mag dan NIET `localhost` zijn (Vercel kan niet naar uw PC).
#   Zet dat naar uw eigen publiek bereikbare Ollama.

# Hardening (zonder auth)
AI_RATE_LIMIT_PER_MINUTE=30
AI_MAX_INPUT_CHARS=8000
